{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction model\n",
    "\n",
    "After we perform feature engieering, now we will make preidction model and evaluartion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "from nltk.util import ngrams\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_nc = '''\n",
    "select cs.cwhen as breaker\n",
    "    , cm.cwhen as child\n",
    "    , cs.message as breaker\n",
    "    , cm.message as child\n",
    "    , Substring(cs.csha,0,8) as broken\n",
    "    , Substring(parent.prev,0,8) as parent \n",
    "    , Substring(child.curr,0,8) as child\n",
    "    , cs.email as breaker\n",
    "    , cm.email as child\n",
    "from\n",
    "impact_pairs as parent\n",
    ", impact_pairs as child\n",
    ", commits as cs\n",
    ", commits as cm\n",
    ",(\n",
    "    (select prev as csha from impact_pairs) \n",
    "    union \n",
    "    (select curr as csha from impact_pairs)\n",
    ") as ip\n",
    ",(\n",
    "    select cs.application as app\n",
    "    , min(cwhen) as minwhen\n",
    "    , max(cwhen) as maxwhen\n",
    "    from \n",
    "    (\n",
    "        (select prev as csha from impact_pairs) \n",
    "        union \n",
    "        (select curr as csha from impact_pairs)\n",
    "    )\n",
    "    as ip\n",
    "    ,commits as cs\n",
    "    ,(\n",
    "        (select application,csha from findbugs_summary_uni) \n",
    "        union \n",
    "        (select application,csha from pmd_uni) \n",
    "        union \n",
    "        (select application,csha from sonarqube_system_uni) \n",
    "    )\n",
    "    as anal\n",
    "    where cs.csha=anal.csha\n",
    "    and cs.csha=ip.csha\n",
    "    and cs.application=anal.application\n",
    "    and cs.application like %s\n",
    "    group by cs.application\n",
    ") as recovered\n",
    "where\n",
    "    cs.application = recovered.app\n",
    "    and cs.cwhen <= recovered.maxwhen\n",
    "    and cs.cwhen >= recovered.minwhen\n",
    "    and cs.csha=ip.csha\n",
    "    and parent.curr=cs.csha\n",
    "    and child.prev=cs.csha\n",
    "    and cm.csha=child.curr\n",
    "    and ip.csha not in\n",
    "    (\n",
    "        select cs.csha\n",
    "        from \n",
    "        (\n",
    "            (select prev as csha from impact_pairs) \n",
    "            union \n",
    "            (select curr as csha from impact_pairs)\n",
    "        )\n",
    "        as ip\n",
    "        ,commits as cs\n",
    "        ,(\n",
    "            (select application,csha from findbugs_summary_uni) \n",
    "            union \n",
    "            (select application,csha from pmd_uni) \n",
    "            union \n",
    "            (select application,csha from sonarqube_system_uni) \n",
    "        )\n",
    "        as anal\n",
    "        where cs.csha=anal.csha\n",
    "        and cs.csha=ip.csha\n",
    "        and cs.application=anal.application\n",
    "    )\n",
    "order by cs.application asc ,  cs.cwhen desc\n",
    "'''\n",
    "\n",
    "sql_c = '''\n",
    "select cs.cwhen as breaker\n",
    "    , cm.cwhen as child\n",
    "    , cs.message as breaker\n",
    "    , cm.message as child\n",
    "    , Substring(cs.csha,0,8) as broken\n",
    "    , Substring(parent.prev,0,8) as parent \n",
    "    , Substring(child.curr,0,8) as child\n",
    "    , cs.email as breaker\n",
    "    , cm.email as child\n",
    "from\n",
    "impact_pairs as parent\n",
    ", impact_pairs as child\n",
    ", commits as cs\n",
    ", commits as cm\n",
    ",(\n",
    "    (select prev as csha from impact_pairs) \n",
    "    union \n",
    "    (select curr as csha from impact_pairs)\n",
    ") as ip\n",
    ",(\n",
    "    select cs.application as app\n",
    "    , min(cwhen) as minwhen\n",
    "    , max(cwhen) as maxwhen\n",
    "    from \n",
    "    (\n",
    "        (select prev as csha from impact_pairs) \n",
    "        union \n",
    "        (select curr as csha from impact_pairs)\n",
    "    )\n",
    "    as ip\n",
    "    ,commits as cs\n",
    "    ,(\n",
    "        (select application,csha from findbugs_summary_uni) \n",
    "        union \n",
    "        (select application,csha from pmd_uni) \n",
    "        union \n",
    "        (select application,csha from sonarqube_system_uni) \n",
    "    )\n",
    "    as anal\n",
    "    where cs.csha=anal.csha\n",
    "    and cs.csha=ip.csha\n",
    "    and cs.application=anal.application\n",
    "    and cs.application like %s\n",
    "    group by cs.application\n",
    ") as recovered\n",
    "where\n",
    "    cs.application = recovered.app\n",
    "    and cs.cwhen <= recovered.maxwhen\n",
    "    and cs.cwhen >= recovered.minwhen\n",
    "    and cs.csha=ip.csha\n",
    "    and parent.curr=cs.csha\n",
    "    and child.prev=cs.csha\n",
    "    and cm.csha=child.curr\n",
    "    and ip.csha in\n",
    "    (\n",
    "        select cs.csha\n",
    "        from \n",
    "        (\n",
    "            (select prev as csha from impact_pairs) \n",
    "            union \n",
    "            (select curr as csha from impact_pairs)\n",
    "        )\n",
    "        as ip\n",
    "        ,commits as cs\n",
    "        ,(\n",
    "            (select application,csha from findbugs_summary_uni) \n",
    "            union \n",
    "            (select application,csha from pmd_uni) \n",
    "            union \n",
    "            (select application,csha from sonarqube_system_uni) \n",
    "        )\n",
    "        as anal\n",
    "        where cs.csha=anal.csha\n",
    "        and cs.csha=ip.csha\n",
    "        and cs.application=anal.application\n",
    "    )\n",
    "order by cs.application asc ,  cs.cwhen desc\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn =  psycopg2.connect(\"dbname='icsme2018_march30' user='postgres' password = 'admin' host='localhost'\")\n",
    "except:\n",
    "    print (\"I am unable to connect to the database\")  \n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(sql_nc, ('apache-%',))\n",
    "pairs_nc = cur.fetchall()\n",
    "cur.execute(sql_c, ('apache-%',))\n",
    "pairs_c = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features<br>\n",
    "1) Message Similarity <br>\n",
    "2) issue number (all of)<br>\n",
    "3) time difference less than 1 hr?<br>\n",
    "4) time messed up?<br>\n",
    "5) same developer?<br>\n",
    "6) Key word in commit message<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>break_time</th>\n",
       "      <th>child_time</th>\n",
       "      <th>break_message</th>\n",
       "      <th>child_message</th>\n",
       "      <th>break_csha</th>\n",
       "      <th>parrent_csha</th>\n",
       "      <th>child_csha</th>\n",
       "      <th>break_email</th>\n",
       "      <th>child_email</th>\n",
       "      <th>compilable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-03 07:07:10</td>\n",
       "      <td>2016-03-07 21:23:34</td>\n",
       "      <td>[CALCITE-1124] Add TIMESTAMPADD, TIMESTAMPDIFF...</td>\n",
       "      <td>Further to [CALCITE-1124], add implementation ...</td>\n",
       "      <td>0b9ea98</td>\n",
       "      <td>cf5d07b</td>\n",
       "      <td>4ac82a3</td>\n",
       "      <td>arina.yelchiyeva@gmail.com</td>\n",
       "      <td>jhyde@apache.org</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-07 17:47:31</td>\n",
       "      <td>2015-12-07 19:06:26</td>\n",
       "      <td>Move code from JdbcImplementor and JdbcRules t...</td>\n",
       "      <td>Remove redundant code from RelToSqlConverter\\n...</td>\n",
       "      <td>980d9f8</td>\n",
       "      <td>eedd3dc</td>\n",
       "      <td>47e0e7c</td>\n",
       "      <td>jhyde@apache.org</td>\n",
       "      <td>jhyde@apache.org</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-20 16:03:21</td>\n",
       "      <td>2015-12-05 14:36:02</td>\n",
       "      <td>[CALCITE-968] Stream-to-relation and stream-to...</td>\n",
       "      <td>Fix up [CALCITE-968]\\n</td>\n",
       "      <td>e9d5060</td>\n",
       "      <td>8281668</td>\n",
       "      <td>937fc46</td>\n",
       "      <td>milinda.pathirage@gmail.com</td>\n",
       "      <td>jhyde@apache.org</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-10-06 13:55:24</td>\n",
       "      <td>2015-10-06 14:09:59</td>\n",
       "      <td>[CALCITE-785] Add \"Piglet\", a subset of Pig La...</td>\n",
       "      <td>Fix Piglet DUMP applied to multisets and struc...</td>\n",
       "      <td>5cee2a1</td>\n",
       "      <td>82ac7b2</td>\n",
       "      <td>26f303e</td>\n",
       "      <td>jhyde@apache.org</td>\n",
       "      <td>jhyde@apache.org</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-09 11:46:58</td>\n",
       "      <td>2015-07-09 15:36:03</td>\n",
       "      <td>[CALCITE-783] Infer collation of Project using...</td>\n",
       "      <td>Complete [CALCITE-783] by fixing some planner ...</td>\n",
       "      <td>c711fed</td>\n",
       "      <td>f7ec3e8</td>\n",
       "      <td>9177063</td>\n",
       "      <td>milinda.pathirage@gmail.com</td>\n",
       "      <td>jhyde@apache.org</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           break_time          child_time  \\\n",
       "0 2016-03-03 07:07:10 2016-03-07 21:23:34   \n",
       "1 2015-12-07 17:47:31 2015-12-07 19:06:26   \n",
       "2 2015-11-20 16:03:21 2015-12-05 14:36:02   \n",
       "3 2015-10-06 13:55:24 2015-10-06 14:09:59   \n",
       "4 2015-07-09 11:46:58 2015-07-09 15:36:03   \n",
       "\n",
       "                                       break_message  \\\n",
       "0  [CALCITE-1124] Add TIMESTAMPADD, TIMESTAMPDIFF...   \n",
       "1  Move code from JdbcImplementor and JdbcRules t...   \n",
       "2  [CALCITE-968] Stream-to-relation and stream-to...   \n",
       "3  [CALCITE-785] Add \"Piglet\", a subset of Pig La...   \n",
       "4  [CALCITE-783] Infer collation of Project using...   \n",
       "\n",
       "                                       child_message break_csha parrent_csha  \\\n",
       "0  Further to [CALCITE-1124], add implementation ...    0b9ea98      cf5d07b   \n",
       "1  Remove redundant code from RelToSqlConverter\\n...    980d9f8      eedd3dc   \n",
       "2                             Fix up [CALCITE-968]\\n    e9d5060      8281668   \n",
       "3  Fix Piglet DUMP applied to multisets and struc...    5cee2a1      82ac7b2   \n",
       "4  Complete [CALCITE-783] by fixing some planner ...    c711fed      f7ec3e8   \n",
       "\n",
       "  child_csha                  break_email       child_email  compilable  \n",
       "0    4ac82a3   arina.yelchiyeva@gmail.com  jhyde@apache.org           1  \n",
       "1    47e0e7c             jhyde@apache.org  jhyde@apache.org           1  \n",
       "2    937fc46  milinda.pathirage@gmail.com  jhyde@apache.org           1  \n",
       "3    26f303e             jhyde@apache.org  jhyde@apache.org           1  \n",
       "4    9177063  milinda.pathirage@gmail.com  jhyde@apache.org           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP = 0\n",
    "NON_COMP = 1\n",
    "\n",
    "df_nc = pd.DataFrame(pairs_nc, columns = ['break_time', 'child_time', 'break_message', 'child_message', 'break_csha', 'parrent_csha', 'child_csha', 'break_email', 'child_email'])\n",
    "df_nc['compilable'] = NON_COMP\n",
    "df_c = pd.DataFrame(pairs_c, columns = ['break_time', 'child_time', 'break_message', 'child_message', 'break_csha', 'parrent_csha', 'child_csha', 'break_email', 'child_email'])\n",
    "df_c['compilable'] = COMP\n",
    "\n",
    "df = pd.concat([df_nc, df_c])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature 1 - Message Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRAMS = 2\n",
    "THRESHOLD = 0.8\n",
    "\n",
    "# def message_sim(row):\n",
    "#     distance = 1 - jaccard_distance(set(ngrams(row['break_message'],N_GRAMS)), set(ngrams(row['child_message'],N_GRAMS)))\n",
    "#     if distance > THRESHOLD:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def message_sim(row):\n",
    "    distance = 1 - jaccard_distance(set(ngrams(row['break_message'],N_GRAMS)), set(ngrams(row['child_message'],N_GRAMS)))\n",
    "    return distance\n",
    "\n",
    "\n",
    "df['feature_1'] = df.apply(message_sim, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature 2 - Issue Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issue_number(row):\n",
    "    issue_number_break = re.findall('[A-Za-z]+[- ]\\d+', row['break_message'])\n",
    "    issue_number_child = re.findall('[A-Za-z]+[- ]\\d+', row['child_message'])\n",
    "\n",
    "    if len(issue_number_break) == 0 or len(issue_number_child) == 0:\n",
    "        return -1\n",
    "    elif issue_number_break == issue_number_child:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "df['feature_2'] = df.apply(issue_number, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature 3 - Time Difference > 1 hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOUR = 3600\n",
    "DAY = HOUR * 24\n",
    "\n",
    "#df['feature_3'] = (df['child_time'] - df['break_time']).dt.total_seconds() > HOUR\n",
    "\n",
    "df['feature_3'] = df.apply(lambda x: 1 if (x['child_time'] - x['break_time']).total_seconds() > HOUR else -1, axis =1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature 4 - whether time messed up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['feature_4'] = (df['child_time'] - df['break_time']).dt.total_seconds() > 0\n",
    "\n",
    "df['feature_4'] = df.apply(lambda x: 1 if (x['child_time'] - x['break_time']).total_seconds() > 0 else -1, axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature 5 - whether same developer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feature_5'] = df['break_email'] == df['child_email']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature 6 - whether contain key words? <br>\n",
    "['compile' 'compilation' '4280' 'sign' 'jakarta' 'missed' 'oops' 'missing' 'breakage' 'mgmt' 'adapted' 'wss4j' 'hamaconfiguration' 'branches' 'bad' 'service' 'conn' 'files' 'abstractserversession' 'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kw = ['missed' , 'oops']\n",
    "# def contain_kw(row):\n",
    "#     issue_number_break = re.findall('[A-Za-z]+[- ]\\d+', row['break_message'])\n",
    "#     if issue_number_break: return 1\n",
    "#     else: return -1\n",
    "    \n",
    "\n",
    "def contain_kw(row):\n",
    "    if  'missed' in  row['break_message'].lower(): \n",
    "        return 1\n",
    "    else: return -1\n",
    "\n",
    "\n",
    "\n",
    "def contain_fix(row):\n",
    "    if 'javadoc' in row['break_message'].lower() : return 1\n",
    "    else: return -1\n",
    "    \n",
    "    \n",
    "# def contain_kw(row):\n",
    "#     issue_number_break = re.findall('[A-Za-z]+[- ]\\d+', row['break_message'])\n",
    "#     if issue_number_break: return 1\n",
    "#     else: return -1\n",
    "    \n",
    "\n",
    "df['feature_6'] = df.apply(contain_kw, axis = 1)\n",
    "df['feature_8'] = df.apply(contain_fix, axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature 7 - Log Time Difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def log_(row):\n",
    "    hour = (row['child_time'] - row['break_time']).total_seconds()/3600.0\n",
    "    if hour >= 1.0/12:\n",
    "        return np.log(hour)\n",
    "    else: return np.log(1.0/12)\n",
    "\n",
    "df['feature_7'] = df.apply(log_, axis =1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['feature_1', 'feature_2', 'feature_3', 'feature_4','feature_6','feature_7','feature_8']].iloc[0:1000]\n",
    "y = df[['compilable']].iloc[0:1000]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y['compilable'], random_state = 0)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pre_proba = model.predict_proba(X_test)\n",
    "y_pre = model.predict(X_test)\n",
    "print('AUC: ', roc_auc_score(y_test, y_pre_proba[:,1]))\n",
    "print('F1: ', f1_score(y_test, y_pre))\n",
    "print(confusion_matrix(y_test, y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
